{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca9b5e9-a985-4b38-a270-cdc6d87d9da1",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:25px;\n",
    "            background-color:#99D8FF;font-size:150%; \n",
    "            letter-spacing:1.0px;background-image: url\">\n",
    "    <p style=\"padding: 8px;text-align: center;color:#464646; border-radius: 10px; padding-top: 15px; padding-bottom: 15px;\"><b><b><span style='color:#99D8FF''></span></b> Hello and welcome to the car ad price forecasting project ! </b></p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c39d7-7ed4-4fa0-b845-33cc25064d58",
   "metadata": {},
   "source": [
    "---\n",
    "#### Team members :\n",
    "> __Raz Elbaz__\n",
    ">\n",
    "> __Noa Anaki__\n",
    "\n",
    "#### Git Link :\n",
    "> __https://github.com/Razelbaz1/Advanced_data_mining_and_analysis_Course__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32655441-c41a-4495-872f-1f2215f0752c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "> In this notebook we will build general functions that are attributed to each column in the data,\n",
    "> which at the end we will activate all of them by a main function called `prepare_data()` in order to predict the prices of vehicles.\n",
    "\n",
    "> The data import at the beginning is for the main data to analyze and show the way and understand what was the motivation for each column.\n",
    "<hr>\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>dear reader:</strong> \n",
    " <br> For your convenience a table of contents is written here below.<br>\n",
    " <br><u>Content summary:</u><br>\n",
    " <br>Chapters 4 - 13 concern everything related to creating functions to deal with cleaning and creating new features that seemed right to us and performing general algorithms in order to prepare the data we have suitable for the world.<br>\n",
    " <br>Chapter 14 is the part where the prepare_date function is activated where all the data is processed according to the functions written above.<br>\n",
    " <br>Chapter 15 and last is the chapter in which all the steps to create the model are presented.<br>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8884b47-f979-41a3-aefb-fc6daf5e6bbe",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<strong>Table of Contents:</strong> \n",
    "</div>\n",
    "<div style=\"text-align: center;\"> \n",
    "\n",
    "1. [Import relevant libraries.](#sec1)\n",
    "2. [Reading data for general analysis.](#sec2)\n",
    "3. [Wrangling data.](#sec3)\n",
    "4. [Columns handling: `manufactor`](#sec4)\n",
    "5. [Columns handling: `model`](#sec5)\n",
    "6. [Columns handling: `Year`](#sec6)\n",
    "7. [Columns handling: `Hand`](#sec7)\n",
    "8. [Columns handling: `Gear`](#sec8)\n",
    "9. [Columns handling: `Engine_type`](#sec9)\n",
    "10. [Columns handling: `capacity_Engine`](#sec10)\n",
    "11. [Columns handling: `Prev_ownership` , `Curr_ownership` , `Description`](#sec11)\n",
    "12. [Columns handling:  `Area`](#sec12)\n",
    "13. [Columns handling:  `Km`](#sec13)\n",
    "14. [prepare_data function & Call prepare_data()](#sec14)\n",
    "15. [Data Preparation & ElasticNet Model Pipeline.](#sec15)\n",
    "16. [Analyze the outputs.](#sec16)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb567c8-8484-4489-8c53-34489eafb847",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec1'></a>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:25px;\n",
    "            background-color:#99D8FF;font-size:150%; \n",
    "            letter-spacing:1.0px;background-image: url\">\n",
    "    <p style=\"padding: 8px;text-align: center;color:#464646; border-radius: 10px; padding-top: 5px; padding-bottom: 5px;\"><b><b><span style='color:#99D8FF''></span></b> Import relevant libraries. </b></p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ea7f24-206e-4ad6-9911-f458164323f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler ,OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV , train_test_split ,KFold , cross_val_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import skew\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42282c04-19cb-49f5-a91a-1aa5ce04ab6b",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec2'></a>\n",
    "<div style=\"color:white;display:fill;border-radius:25px;\n",
    "            background-color:#99D8FF;font-size:150%; \n",
    "            letter-spacing:1.0px;background-image: url\">\n",
    "    <p style=\"padding: 8px;text-align: center;color:#464646; border-radius: 10px; padding-top: 5px; padding-bottom: 5px;\"><b><b><span style='color:#99D8FF''></span></b> Reading data for general analysis. </b></p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aec7a2b-6878-4d05-b394-5c964f8ced67",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'dataset.csv'\n",
    "data = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f882b8-e65d-4f5c-8132-18ddac059ab5",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec3'></a>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:25px;\n",
    "            background-color:#99D8FF;font-size:150%; \n",
    "            letter-spacing:1.0px;background-image: url\">\n",
    "    <p style=\"padding: 8px;text-align: center;color:#464646; border-radius: 10px; padding-top: 5px; padding-bottom: 5px;\"><b><b><span style='color:#99D8FF''></span></b> Wrangling data. </b></p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d516d2bb-a992-44c8-8237-21a6ab761a4c",
   "metadata": {},
   "source": [
    ">\n",
    "> __1. Duplicates handling:__ Check for duplicate rows and remove them. \n",
    "\n",
    "> __2. Columns handling:__ In this part we will have to check a lot of factors corresponding to that column.\n",
    "> <div> i. -Does the column type match how it should be. <div> ii. -Checking for duplicates in category columns in order to avoid ambiguity. <div> iii. -Dealing with missing values: We will make decisions regarding this issue on a case-by-case basis, we will make assumptions and according to them we will test the model, there may be changes during the analysis. <div> iv. -Columns that are not relevant to the model will be removed in advance in order not to damage the predictive ability of the model and we will explain this as much as possible </div>\n",
    "\n",
    "\n",
    "\n",
    ">  __3. Data cleaning:__ Work flow is the same as section 2(iii) with the addition of various calculations.\n",
    "We will explain actions to be taken in such a case.<div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9fa1d-4e9c-4aa7-b1dd-21114a3d2195",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>Duplicates handling:</strong> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f595304f-4d4f-4fce-acee-189176e0e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_Duplicates(data):\n",
    "    # Identify duplicate rows\n",
    "    data.drop_duplicates(inplace = True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18087c40-898b-42e5-a923-70c0d4991932",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec4'></a>\n",
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>Columns handling:</strong> <code>manufactor</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063cb73-b3ad-4182-8641-afdc463d2890",
   "metadata": {},
   "source": [
    " Ensuring that we have consistent and accurate categorical data is crucial before we perform any encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423f7251-ccfa-415a-b3b4-3f3809ef1005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['יונדאי', 'ניסאן', 'סוזוקי', 'טויוטה', 'קיה', 'אאודי', 'סובארו',\n",
       "       'מיצובישי', 'מרצדס', 'ב.מ.וו', 'אופל', 'הונדה', 'פולקסווגן',\n",
       "       'שברולט', 'מאזדה', 'וולוו', 'סקודה', 'פורד', 'Lexsus', 'קרייזלר',\n",
       "       'סיטרואן', \"פיג'ו\", 'רנו', 'לקסוס', 'דייהטסו', 'מיני',\n",
       "       'אלפא רומיאו'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['manufactor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc17300f-2163-4871-a4e2-ffdf9e32c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to standardize manufacturer names using regex\n",
    "def standardize_manufactor(name):\n",
    "    if re.search(r'\\b(Lexsus|לקסוס)\\b', name, re.IGNORECASE):\n",
    "        return 'לקסוס'\n",
    "    elif re.search(r'\\b(b\\.m\\.w|ב\\.מ\\.וו|bmw)\\b', name, re.IGNORECASE):\n",
    "        return 'ב.מ.וו'\n",
    "    elif re.search(r'\\b(Mercedes|מרצדס|Mercedez|Merc-Benz)\\b', name, re.IGNORECASE):\n",
    "        return 'מרצדס'\n",
    "    elif re.search(r'\\b(Audi|אאודי)\\b', name, re.IGNORECASE):\n",
    "        return 'אאודי'\n",
    "    elif re.search(r'\\b(opal|אופל)\\b', name, re.IGNORECASE):\n",
    "        return 'אופל'\n",
    "    elif re.search(r'\\b(Alpha romeo|אלפא רומיאו)\\b', name, re.IGNORECASE):\n",
    "        return 'אלפא רומיאו'\n",
    "    elif re.search(r'\\b(Daihatsu|דייהטסו)\\b', name, re.IGNORECASE):\n",
    "        return 'דייהטסו'\n",
    "    elif re.search(r'\\b(Honda|הונדה)\\b', name, re.IGNORECASE):\n",
    "        return 'הונדה'\n",
    "    elif re.search(r'\\b(Volvo|וולוו)\\b', name, re.IGNORECASE):\n",
    "        return 'וולוו'\n",
    "    elif re.search(r'\\b(Toyota|טויוטה)\\b', name, re.IGNORECASE):\n",
    "        return 'טויוטה'\n",
    "    elif re.search(r'\\b(Tesla|טסלה)\\b', name, re.IGNORECASE):\n",
    "        return 'טסלה'\n",
    "    elif re.search(r'\\b(jaguar|יגואר)\\b', name, re.IGNORECASE):\n",
    "        return 'יגואר'\n",
    "    elif re.search(r'\\b(Hyundai|יונדאי)\\b', name, re.IGNORECASE):\n",
    "        return 'יונדאי'\n",
    "    elif re.search(r'\\b(Mazda|מאזדה)\\b', name, re.IGNORECASE):\n",
    "        return 'מאזדה'\n",
    "    elif re.search(r'\\b(Mini|מיני)\\b', name, re.IGNORECASE):\n",
    "        return 'מיני'\n",
    "    elif re.search(r'\\b(Mitsubishi|מיצובישי)\\b', name, re.IGNORECASE):\n",
    "        return 'מיצובישי'\n",
    "    elif re.search(r'\\b(Nissan|ניסאן)\\b', name, re.IGNORECASE):\n",
    "        return 'ניסאן'\n",
    "    elif re.search(r'\\b(Subaru|סובארו)\\b', name, re.IGNORECASE):\n",
    "        return 'סובארו'\n",
    "    elif re.search(r'\\b(Suzuki|סוזוקי)\\b', name, re.IGNORECASE):\n",
    "        return 'סוזוקי'\n",
    "    elif re.search(r'\\b(Seat|סיאט)\\b', name, re.IGNORECASE):\n",
    "        return 'סיאט'\n",
    "    elif re.search(r'\\b(Citroen|סיטרואן)\\b', name, re.IGNORECASE):\n",
    "        return 'סיטרואן'\n",
    "    elif re.search(r'\\b(Skoda|סקודה)\\b', name, re.IGNORECASE):\n",
    "        return 'סקודה'\n",
    "    elif re.search(r'\\b(Volkswagen|פולקסווגן)\\b', name, re.IGNORECASE):\n",
    "        return 'פולקסווגן'\n",
    "    elif re.search(r'\\b(Ford|פורד)\\b', name, re.IGNORECASE):\n",
    "        return 'פורד'\n",
    "    elif re.search(r'\\b(Peugeot|פיג\\'ו)\\b', name, re.IGNORECASE):\n",
    "        return 'פיג\\'ו'\n",
    "    elif re.search(r'\\b(Fiat|פיאט)\\b', name, re.IGNORECASE):\n",
    "        return 'פיאט'\n",
    "    elif re.search(r'\\b(Kia|קיה)\\b', name, re.IGNORECASE):\n",
    "        return 'קיה'\n",
    "    elif re.search(r'\\b(Chrysler|קרייזלר)\\b', name, re.IGNORECASE):\n",
    "        return 'קרייזלר'\n",
    "    elif re.search(r'\\b(Renault|רנו)\\b', name, re.IGNORECASE):\n",
    "        return 'רנו'\n",
    "    elif re.search(r'\\b(Chevrolet|שברולט)\\b', name, re.IGNORECASE):\n",
    "        return 'שברולט'\n",
    "    # Add more regex rules as needed\n",
    "    return name\n",
    "\n",
    "# Standardize the 'manufactor' column using regex\n",
    "def standardize_column_regex(df, column):\n",
    "    df[column] = df[column].apply(standardize_manufactor)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f9ed7-c96e-44b2-ac9a-1eb244922ef2",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec5'></a>\n",
    "\n",
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>Columns handling:</strong> <code>model</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d6bad7-8686-41da-ba98-afdd61078e9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i35', 'ניסאן מיקרה', 'סוזוקי סוויפט', 'אוריס', 'פיקנטו',\n",
       "       'אאודי A1', 'אימפרזה', 'ASX', '220', '525', 'מוקה', 'פורטה', ' Q3',\n",
       "       'סיוויק סדאן', 'סוזוקי SX4 קרוסאובר', 'קורולה', 'גולף', 'פאסאט',\n",
       "       'ספארק', 'מאזדה 3', 'ניסאן נוט', 'סול', 'V40 CC', 'לנסר ספורטבק',\n",
       "       'i10', 'אאודי A3', ' A1', 'סקודה פאביה\\r\\n (2012)', 'אוקטביה',\n",
       "       'CIVIC', 'איוניק', 'סונטה', 'i30', 'C-HR', 'מאליבו', 'ריו',\n",
       "       'פוקוס', 'סקודה אוקטביה (2014)', 'X1', 'אוואו', 'סיוויק',\n",
       "       'סקודה ראפיד (2015)', ' E-Class', ' S7', 'אפלנדר', 'SVX',\n",
       "       'סוזוקי איגניס', 'ספייס סטאר', 'לקסוס IS300h', \"גראנד, וויאג'ר\",\n",
       "       'C4', '2008', 'סטוניק', 'פולו', 'S60', 'אאודי RS5', \"ג'אז הייבריד\",\n",
       "       'סוזוקי SX4', 'ג`טה', ' A4', 'אס-מקס', 'נירו', 'אינסייט',\n",
       "       'רנו קליאו', '3', 'אאודי All Road', 'פאסאט CC', ' S-Class',\n",
       "       'CADDY COMBI', 'אסטרה', 'XV', 'סיוויק סדאן החדשה', 'אאודי A5',\n",
       "       '316', 'C3', 'סדרה 5', 'אקורד', 'i25', 'C1', 'יאריס',\n",
       "       'לקסוס IS250', 'V40', 'סדרה 1', 'סקודה אוקטביה (2013)', 'סראטו',\n",
       "       'מאזדה 5', 'סוזוקי סוויפט החדשה', 'מאזדה 2', '5',\n",
       "       'רנו קליאו דור 4', 'קורבט', \"אטראז'\", 'i20', ' A3', '200', 'B4',\n",
       "       \"ג'טה\", '308', \"סיוויק האצ'בק החדשה\",\n",
       "       'סקודה אוקטביה ספייס\\r\\n (2015)', 'מוקה X',\n",
       "       'סקודה פאביה\\r\\n (2016)', 'רנו גרנד סניק',\n",
       "       'סקודה פאביה\\r\\n (2013)', 'זאפירה', 'אינסיגניה', '6',\n",
       "       'לקסוס CT200H', 'אורלנדו', 'ניסאן אלתימה', 'סוזוקי אלטו',\n",
       "       'סוזוקי קרוסאובר', '108', 'JAZZ', 'DS3', 'פריוס', 'שירוקו',\n",
       "       \"ניסאן ג'וק JUKE\", 'XCEED', 'רנו מגאן אסטייט / גראנד טור',\n",
       "       'סקודה סופרב (2013)', 'סקודה סופרב (2016)', 'ספייס',\n",
       "       'סקודה אוקטביה (2015)', 'רנו פלואנס', 'ACCORD', ' SLK',\n",
       "       \"סיוויק האצ'בק\", 'סקודה פאביה\\r\\n (2015)', 'אלנטרה', 'אאודי S7',\n",
       "       'סוזוקי בלנו', 'טראקס', 'FR-V', 'ניסאן סנטרה', 'סיריון', \"ג'אז\",\n",
       "       'גרנדיס', 'סקודה אוקטביה (2016)', 'סקודה סופרב (2015)', 'פרייד',\n",
       "       'מאזדה 6', 'סלבריטי', 'טריוס', 'רנו פלואנס חשמלי', 'פאביה ספייס',\n",
       "       '120i', 'קאונטרימן', 'אלפא רומיאו 159', 'אלפא רומיאו מיטו / MITO',\n",
       "       'אקווינוקס', '208', ' A6', 'סקודה סופרב (2014)', 'חיפושית',\n",
       "       'ראפיד', 'B3', 'ורסו', 'קורסה', 'ייטי', 'אאודי A6', 'אדם',\n",
       "       \"אלפא רומיאו ג'ולייטה\", 'ג`אז', 'סוזוקי סדן', 'אאוטלנדר', 'מוסטנג',\n",
       "       'לקסוס GS300', '508', 'לקסוס RC', 'סקודה סופרב (2011)', 'i30CW',\n",
       "       'סקודה אוקטביה ספייס\\r\\n (2016)', 'ולוסטר', 'אאודי A4',\n",
       "       'סקודה אוקטביה ספייס (2015)', 'קופר', ' CLK', ' A5',\n",
       "       'סקודה פאביה (2012)', 'נירו EV', 'האצ`בק', ' RS5', 'קרוז',\n",
       "       'סוזוקי ספלאש', 'גולף פלוס', 'סופרב', 'לקסוס IS300H',\n",
       "       'ראפיד ספייסבק', 'אוקטביה קומבי', 'נירו PHEV', 'S80', 'לאונה',\n",
       "       'אקליפס', 'סוניק', '307CC', 'אאוטבק', 'סקודה אוקטביה (2010)',\n",
       "       'סדרה 3', 'דייהטסו טריוס', 'אודסיי', 'סקודה ייטי (2012)', 'קרניבל',\n",
       "       'סקודה אוקטביה RS (2014)', 'סוזוקי סלריו', 'AX', 'פיאסטה',\n",
       "       'גראנד, וויאג`ר', ' V- CLASS', 'לג`נד', 'C30', 'I-MIEV',\n",
       "       'סקודה ראפיד (2014)', 'סקודה סופרב (2012)',\n",
       "       'סקודה פאביה\\r\\n (2014)', 'סקודה רומסטר\\r\\n (2014)', 'ONE',\n",
       "       'אאודי Q3', 'אלפא רומיאו מיטו', 'רנו קפצ`ור', 'שרמנט', 'גלאקסי',\n",
       "       'ניסאן פרימרה', 'וויאג`ר', 'M1', 'גולף GTI', 'GT3000', ' R8',\n",
       "       'סקודה אוקטביה (2011)', 'סיוויק סטיישן', '300C', 'אימפלה', 'ספיה',\n",
       "       'קורסה החדשה', 'סקודה רומסטר\\r\\n (2013)', 'סקודה ראפיד (2013)',\n",
       "       'סקודה פאביה ספייס (2016)', ' C-Class', 'INSIGHT', \"טרג'ט\", 'CX',\n",
       "       'קאמרי', '5008', 'אונסיס', ' E-Class קופה / קבריולט', 'סיד', '530',\n",
       "       'i40', 'רנו קליאו אסטייט', 'פאביה', '301', 'C5', '320',\n",
       "       'סקודה רומסטר (2012)', 'קרוז החדשה', 'סקודה רומסטר (2015)',\n",
       "       ' C-Class Taxi', '318', '2', ' C-CLASS קופה', 'מריבה',\n",
       "       'חיפושית חדשה', 'קופה', 'דייהטסו סיריון', 'סיוויק הייבריד',\n",
       "       'קורסיקה', 'קונקט', ' C-Class קופה', 'RCZ', 'ניסאן קווסט',\n",
       "       'סקודה אוקטביה (2012)', 'אאודי S5', 'אאודי S3', 'קאנטרימן',\n",
       "       'רנו 25', 'סיטיגו / Citygo', ' E- CLASS',\n",
       "       'סקודה רומסטר\\r\\n (2015)', 'לנסר', '325', 'ניסאן מקסימה', 'one',\n",
       "       'טוראן', 'ניסאן אלמרה', 'אוונסיס', 'סקודה פאביה\\r\\n (2011)', '523',\n",
       "       'לנסר הדור החדש', '106'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['model'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a209ed-290d-453c-b0d2-b575f5ca240f",
   "metadata": {},
   "source": [
    "_By executing `data['model'].unique()`, we aim to verify that all unique model names have been correctly standardized and no duplicates remain due to case or formatting inconsistencies._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d28dd7-cc96-42a1-9441-aecd4ab3518a",
   "metadata": {},
   "source": [
    "> In a simple test first we will make sure that if the manufacturer's name is in the model column - we will remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5794430d-f637-4bba-9c3d-652543717f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_manufactor_name_in_model_col(data):\n",
    "    for index, row in data.iterrows():\n",
    "        manufactor = str(row['manufactor'])\n",
    "        model = str(row['model'])\n",
    "        if manufactor in model:\n",
    "            data.at[index, 'model'] = model.replace(manufactor,'').strip()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1595d160-47ae-4429-b1e4-0e9da16f0be5",
   "metadata": {},
   "source": [
    ">In the next function we will refer to more complex cases, common words that may appear, spaces, unwanted signs and identical names to some of the models that\n",
    ">\n",
    ">we would like to unify, remove and replace with a proper character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e994d5-ed68-4140-8773-d134240fd92f",
   "metadata": {},
   "source": [
    "> According to this column we know, given a mining method, what are the general possibilities to make a mistake and fill in wrong values:\n",
    "> \n",
    "> Mistakes such as creating the model value with the name of the manufacturer and the year of the vehicle.\n",
    "> \n",
    "> We will write code to address this repetitive action pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2906a3fd-678a-4da3-840d-57e48d432fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and standardize the model names\n",
    "def clean_model_name(model_name):\n",
    "    # Remove unwanted characters\n",
    "    model_name = re.sub(r'[\\r\\n\\t]', ' ', model_name)\n",
    "    model_name = re.sub(r'\\(.*?\\)', '', model_name)\n",
    "    model_name = re.sub(r'\\s+', ' ', model_name).strip()\n",
    "    model_name = re.sub(r'ה?חדש(ה)?', '', model_name).strip()\n",
    "    model_name = re.sub(r'ה?סדרה?', '', model_name).strip()\n",
    "    data['model'] = data['model'].str.strip()    \n",
    "    # Correct known duplicates and standardize to Hebrew\n",
    "    model_name = re.sub(r'\\bCivic\\b', 'סיוויק', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\bSX4\\b', 'SX4', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\bS6\\b', 'S6', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\bOne\\b', 'ONE', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\bJuke\\b', \"ג'וק'\", model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\bJazz\\b', \"ג'אז\", model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\bGolf\\b', 'גולף', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\bFocus\\b', 'פוקוס', model_name, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Specific standardization for Nissan Juke\n",
    "    model_name = re.sub(r\"\\bג'וק ג'וק\\b\", \"ג'וק\", model_name, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Specific standardization for Suzuki SX4\n",
    "    model_name = re.sub(r'\\b(SX4 קרוסאובר|קרוסאובר)\\b', 'SX4', model_name, flags=re.IGNORECASE)\n",
    "\n",
    "    # Specific standardization for Kia Niro and its variants\n",
    "    model_name = re.sub(r'\\bנירו ?(ev|phev)?\\b', 'נירו', model_name, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Specific standardization for Opel Mokka\n",
    "    model_name = re.sub(r'\\bמוקה x\\b', 'מוקה', model_name, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Specific standardization for Honda models\n",
    "    model_name = re.sub(r'\\b(סיוויק הייבריד|סיוויק סדאן|סיוויק סטיישן|סיוויק האצ\\'בק|סיוויק|סיוויק האצ’בק)\\b', 'סיוויק', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\b(ג\\'אז הייבריד|ג\\'אז|ג\\'אז הייבריד|ג\\'אז|ג\\'אז)\\b', 'ג\\'אז', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\b(accord|אקורד)\\b', 'ACCORD', model_name, flags=re.IGNORECASE)\n",
    "\n",
    "    # Specific standardization for Mazda models\n",
    "    model_name = re.sub(r'\\b(2|3|5|6)\\b', r'\\1', model_name, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Specific standardization for Peugeot models\n",
    "    model_name = re.sub(r'\\b(108|208|308|508|5008|2008)\\b', r'\\1', model_name, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Specific standardization for Renault models\n",
    "    model_name = re.sub(r'\\b(fluence|קליאו|מגאן|25|גרנד סניק|קפצ\\'ור|פלואנס)\\b', r'\\1', model_name, flags=re.IGNORECASE)\n",
    "\n",
    "    # Specific standardization for Mini models\n",
    "    model_name = re.sub(r'\\b(קאנטרימן|קאונטרימן)\\b', 'קאנטרימן', model_name, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Specific standardization for Alfa Romeo models\n",
    "    model_name = re.sub(r'\\b(מיטו / mito|מיטו|ג\\'ולייטה)\\b', 'מיטו', model_name, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Specific standardization for Chrysler models\n",
    "    model_name = re.sub(r'\\b(וויאג`ר|גראנד,? וויאג\\'ר)\\b', 'גראנד וויאג\\'ר', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\b(g|ג)\\s*וויאג\\'ר\\b', 'גראנד וויאג\\'ר', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\b(וויאג`ר|גראנד,? וויאג\\'ר|גראנד וויאג\\'ר)\\b', 'גראנד וויאג\\'ר', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\b(וויאג`ר|גראנד,? וויאג\\'ר|גראנד וויאג\\'ר|גראנד, גראנד וויאג\\'ר)\\b', 'גראנד וויאג\\'ר', model_name, flags=re.IGNORECASE)\n",
    "\n",
    "    # Specific standardizations for Mercedes models\n",
    "    model_name = re.sub(r'\\bE[-\\s]?class\\b', 'E-Class', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\bC[-\\s]?class\\b', 'C-Class', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\bC-Class Taxi\\b', 'C-Class', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\bE-Class קופה / קבריולט\\b', 'E-Class', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\bC-Class קופה\\b', 'C-Class', model_name, flags=re.IGNORECASE)\n",
    "    model_name = re.sub(r'\\be- class\\b', 'E-Class', model_name, flags=re.IGNORECASE)\n",
    "\n",
    "    # Add more replacement rules as needed\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ac4a6-1bd5-45b3-8598-84db38fc0f5c",
   "metadata": {},
   "source": [
    "> converting to lowercase and removing extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6e5f79-6a40-4c18-bc11-f04b7c3af5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize model names by converting to lowercase and removing extra spaces\n",
    "def normalize_model_name(model_name):\n",
    "    return re.sub(r'\\s+', ' ', model_name.lower()).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7c1af-fc4d-4f30-8c9d-f89ca17e1e6d",
   "metadata": {},
   "source": [
    "> Checking vehicle models according to each manufacturer.\n",
    ">\n",
    "> You can check with this code before running the cleaning functions how much the cleaning has reduced,\n",
    ">\n",
    "> cleaned meaningless characters and unified in favor of reducing the manufacturers' models."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0f44ebe-671a-49f4-9f0c-8f328b06ef3c",
   "metadata": {},
   "source": [
    "# Create a dictionary for manufacturers and their models\n",
    "manufactor_model_dict = {}\n",
    "for _, row in data.iterrows():\n",
    "    manufactor = row['manufactor']\n",
    "    model = row['model']\n",
    "    if manufactor not in manufactor_model_dict:\n",
    "        manufactor_model_dict[manufactor] = set()\n",
    "    manufactor_model_dict[manufactor].add(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5ca7cba-968f-47bd-9d3b-538afcd8d358",
   "metadata": {},
   "source": [
    "# Convert sets to lists and print the dictionary\n",
    "for manufactor in manufactor_model_dict:\n",
    "    manufactor_model_dict[manufactor] = list(manufactor_model_dict[manufactor])\n",
    "    print(f\"{manufactor}: {manufactor_model_dict[manufactor]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62598f1-82a6-47a1-9940-7aa90457a5ad",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec6'></a>\n",
    "\n",
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>Columns handling:</strong> <code>Year</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6429557a-4074-4cd8-81dc-5a8945138300",
   "metadata": {},
   "source": [
    "Creating ranges for the Year column can help the model by reducing the number of unique categories and capturing trends over different periods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9786bfda-a781-4826-9c16-abfe3811c448",
   "metadata": {},
   "source": [
    "Quantile Calculation and Unique Bin Edges:\n",
    "\n",
    "The quantiles are calculated using np.linspace to ensure even distribution.\n",
    "\n",
    "The bin edges are ensured to be unique to avoid overlapping ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5691b4ba-ede1-49e4-abbf-3403dbf4b233",
   "metadata": {},
   "source": [
    "Label Adjustment:\n",
    "\n",
    "The labels are adjusted to accurately reflect the range intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6126c79-5245-4157-9888-a7b037c9befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dynamically bin the Year column\n",
    "def bin_year_column(data, num_bins=5):\n",
    "    # Calculate the quantiles for the number of bins\n",
    "    quantiles = np.linspace(0, 1, num_bins + 1)\n",
    "    bin_edges = data['Year'].quantile(quantiles).unique()\n",
    "    \n",
    "    # Ensure unique bin edges\n",
    "    bin_edges = np.unique(bin_edges)\n",
    "    \n",
    "    # Adjust the upper bound to include the maximum year\n",
    "    bin_edges[-1] = data['Year'].max() + 1\n",
    "\n",
    "    # Create labels for bins\n",
    "    labels = [f'{int(bin_edges[i])}-{int(bin_edges[i+1])}' for i in range(len(bin_edges) - 1)]\n",
    "\n",
    "    # Bin the Year column and create a new column\n",
    "    data['Year_range'] = pd.cut(data['Year'], bins=bin_edges, labels=labels, include_lowest=True, right=False)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07482046-b1ef-4518-99f2-ac44d8728270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2015, 2018, 2010, 2016, 2012, 2009, 2003, 2017, 2013, 2008, 2014,\n",
       "       2007, 2011, 2020, 2023, 1988, 2021, 2019, 1990, 2004, 1999, 2005,\n",
       "       2022, 2006, 2002, 1983, 1998, 2000, 1995], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f84785-d234-4193-978a-02695f6f5c1b",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec7'></a>\n",
    "\n",
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>Columns handling:</strong> <code>Hand</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a3585b-05d4-4d49-8897-1f4d2a08a869",
   "metadata": {},
   "source": [
    ">A numerical column that signifies the number of owners who were on the vehicle:\n",
    ">\n",
    ">The higher the number, the lower the value of the car.\n",
    ">\n",
    ">This column can help the built model to get an indication that the value of the car will be reduced and help us neutralize doubts about an expected price\n",
    ">\n",
    ">due to the nature of the vehicle that may be confusing if it is prestigious in terms of model and manufacturer or relatively new, innovative year or low\n",
    ">\n",
    ">number of kilometers on the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60af5eab-8922-4cb6-9d49-75d4dec05778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  1,  3,  4,  5,  6,  7,  8,  9, 10], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Hand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6a92a5-5178-441f-a86f-5a1b73da9d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Hand'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a371e339-6966-4252-abba-a958fa6d2f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['Hand'],bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cd2f0eb-60e6-4197-ac00-b06d2fa2fb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1500.000\n",
       "mean        2.349\n",
       "std         1.229\n",
       "min         1.000\n",
       "25%         1.000\n",
       "50%         2.000\n",
       "75%         3.000\n",
       "max        10.000\n",
       "Name: Hand, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Hand'].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b15be509-7b2a-4724-b000-cfe56ee772e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Hand\n",
       "min      1.000\n",
       "max     10.000\n",
       "mean     2.349\n",
       "median   2.000\n",
       "std      1.229"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.agg({\"Hand\": [\"min\", \"max\",\"mean\", \"median\",\"std\"]}).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad4257-ba66-4689-a18e-e3f0fb6c611b",
   "metadata": {},
   "source": [
    "> <hr>\n",
    "> <u>Function Explanation:</u>\n",
    "> \n",
    "> The function `handle_hand_column` processes the \"Hand\" column in the dataset, which represents the number of previous owners of a vehicle.\n",
    "> \n",
    "> <u>The steps involved are:</u>\n",
    "> \n",
    "> <u>1.</u> Filling Missing Values: Any missing values in the \"Hand\" column are filled with the median value of the column.\n",
    ">\n",
    ">    This approach ensures that the missing values do not skew the data and maintains the central tendency of the data.\n",
    ">\n",
    "> <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f838fe74-22c2-4066-9032-5ed2a4f4522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_hand_column(data):\n",
    "    # Calculate the median and round it up if it's not an integer\n",
    "    median_hand = data['Hand'].median()\n",
    "    if not median_hand.is_integer():\n",
    "        median_hand = np.ceil(median_hand)\n",
    "    \n",
    "    # Fill missing values with the (possibly rounded up) median\n",
    "    data['Hand'] = data['Hand'].fillna(median_hand)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7e64f7-79d0-42f9-b83c-92f9cd674e0b",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec8'></a>\n",
    "\n",
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>Columns handling:</strong> <code>Gear</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ac998-3a84-4b76-86bd-dd8d605f78e6",
   "metadata": {},
   "source": [
    "The \"Gear\" column in our dataset contains the type of gear mechanism each car has. This column is categorical, with a finite number of possible gear types. Our data shows the following unique gear types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2187517-675e-43e8-b9ae-5b1fe9ee5cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "אוטומטית     1342\n",
       "ידנית          79\n",
       "טיפטרוניק      45\n",
       "רובוטית        31\n",
       "אוטומט          1\n",
       "לא מוגדר        1\n",
       "Name: Gear, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gear'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c12da4-67be-4870-98a3-9a4d3bad2f61",
   "metadata": {},
   "source": [
    "> It is evident and logical in the world that most vehicles are based on an automatic transmission,\n",
    "> \n",
    "> for the sake of simplifying the model relatively we can use an opportunity here to lighten the number of categories for this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb83355-15c0-4a7b-b06a-f272aad96bd5",
   "metadata": {},
   "source": [
    "> <u>1. Inconsistent Naming:</u>\n",
    "> The gear types are represented inconsistently.\n",
    ">\n",
    "> For example, 'אוטומטית' and 'אוטומט' refer to the same gear type.\n",
    ">\n",
    "><u>2. Missing and Undefined Values:</u>\n",
    "> There are missing values (nan) and entries labeled as 'לא מוגדר' which do not provide any meaningful information about the gear type.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491719b-7071-465b-9676-ee32dde9409b",
   "metadata": {},
   "source": [
    "><u> Motivation for Standardizing Gear Types : </u>\n",
    ">\n",
    "><u> Consistency:</u>\n",
    "> To ensure consistency in the dataset, we need to standardize the names of the gear types.\n",
    "> \n",
    "> This helps in reducing redundancy and avoids treating the same gear type as different due to naming inconsistencies.\n",
    "\n",
    "><u> Handling Missing Values:</u>\n",
    "> Missing values in the \"Gear\" column can lead to issues in the analysis and modeling process.\n",
    "> \n",
    "> By filling these missing values with a specific category, we ensure that every entry in the column is accounted for, improving the quality and robustness of our data.\n",
    "\n",
    "><u> Steps to Handle the Gear Column :</u>\n",
    "> \n",
    "><u>Standardizing Gear Names:</u>\n",
    "> We use a dictionary to map various representations of gear types to a standardized Hebrew format. This ensures that 'automatic',\n",
    ">\n",
    "> 'auto', 'אוטומטי', and 'אוטומט' are all mapped to 'אוטומטית'.\n",
    "\n",
    "><u> Filling Missing and Undefined Values:</u>\n",
    "> We treat 'undefined' as missing and fill all missing values with the most common gear type in the dataset.\n",
    "> \n",
    "> This choice is based on the assumption that the most common gear type is likely to be a reasonable default for missing entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8558af-25ec-42f8-ac1a-c9496dedab4b",
   "metadata": {},
   "source": [
    "> <hr>\n",
    "> Using a dictionary to map the options is not the most efficient way or covers all the options,\n",
    "> but here we assume because there are not many types in the field of car gear - we will allow it.\n",
    "> <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09c099c-cbd5-4aae-9030-9f59b793ea12",
   "metadata": {},
   "source": [
    "> <hr>\n",
    "\n",
    "> `Auto_Gear` column:\n",
    "> \n",
    "> is a new column with the help of which we have created in which we are reducing the categories of vehicle gear types in order to reduce the amount of >categories.\n",
    "> <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c1e7439-601b-4297-8ac6-ad0de990e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize gear names\n",
    "def standardize_gear(gear):\n",
    "    # Standardization dictionary for Gear types\n",
    "    gear_mapping = {\n",
    "        'automatic': 'אוטומטי',\n",
    "        'auto': 'אוטומטי',\n",
    "        'אוטומטית': 'אוטומטי',\n",
    "        'אוטומט': 'אוטומטי',\n",
    "        'tiptronic': 'טיפטרוניק',\n",
    "        'manual': 'ידני',\n",
    "        'ידני': 'ידני',\n",
    "        'robotic': 'רובוטי',\n",
    "        'רובוטית': 'רובוטי',\n",
    "        'undefined': np.nan,  # Treat undefined as missing\n",
    "        'לא מוגדר': np.nan\n",
    "    }\n",
    "    \n",
    "    if pd.isna(gear):\n",
    "        return gear\n",
    "    gear = gear.lower().strip()\n",
    "    return gear_mapping.get(gear, gear)\n",
    "\n",
    "# Function to handle missing and undefined gear values\n",
    "def handle_gear_column(data):\n",
    "    # Standardize gear names\n",
    "    data['Gear'] = data['Gear'].apply(standardize_gear)\n",
    "    \n",
    "    # Fill missing and undefined values with the most common gear type\n",
    "    most_common_gear = data['Gear'].mode()[0]\n",
    "    data['Gear'] = data['Gear'].fillna(most_common_gear)\n",
    "   \n",
    "    # Create new column Auto_Gear\n",
    "    data['Auto_Gear'] = (data['Gear'] != 'אוטומטי').astype(int).astype('category')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422be23a-84f2-4fc9-acdd-af5fa09d90e3",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec9'></a>\n",
    "\n",
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>Columns handling:</strong> <code>Engine_type</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e227f7-fc9e-4270-b958-2fee16b8ad6d",
   "metadata": {},
   "source": [
    "We will act here in a similar way to the car gear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55d7e7cf-5cb6-4799-95df-8d9384f69aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['בנזין', 'דיזל', 'גז', 'היברידי', 'היבריד', 'טורבו דיזל', nan,\n",
       "       'חשמלי'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Engine_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ca1e28e-4da4-4607-86b4-4db5cf0ce5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize engine types\n",
    "def standardize_engine_type(engine_type):\n",
    "    # Standardization dictionary for Engine types\n",
    "    engine_type_mapping = {\n",
    "        'gasoline': 'בנזין',\n",
    "        'diesel': 'דיזל',\n",
    "        'turbo diesel': 'טורבו דיזל',\n",
    "        'gas': 'גז',\n",
    "        'hybrid': 'היברידי',\n",
    "        'היבריד': 'היברידי',\n",
    "        'היברידי': 'היברידי',\n",
    "        'electrical': 'חשמלי',\n",
    "        'חשמלי': 'חשמלי',\n",
    "        'undefined': np.nan,  # Treat undefined as missing\n",
    "        'לא מוגדר': np.nan\n",
    "    }\n",
    "\n",
    "    if pd.isna(engine_type):\n",
    "        return engine_type\n",
    "    engine_type = engine_type.lower().strip()\n",
    "    return engine_type_mapping.get(engine_type, engine_type)\n",
    "\n",
    "# Function to handle missing and undefined engine type values\n",
    "def handle_engine_type_column(data):\n",
    "    # Standardize engine types\n",
    "    data['Engine_type'] = data['Engine_type'].apply(standardize_engine_type)\n",
    "    \n",
    "    # Fill missing and undefined values with the most common engine type\n",
    "    most_common_engine_type = data['Engine_type'].mode()[0]\n",
    "    data['Engine_type'] = data['Engine_type'].fillna(most_common_engine_type)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d68750-a224-4711-9e35-ef306418a1cf",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec10'></a>\n",
    "\n",
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>Columns handling:</strong> <code>capacity_Engine</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4691615d-1715-492e-9b6e-554b719b042e",
   "metadata": {},
   "source": [
    "> In terms of engine volume, we also checked here the distribution of the data and according to them we established relatively clear rules for what to do with\n",
    ">\n",
    "> each range of engine volume.\n",
    "> Dealing with missing values.\n",
    "> Extreme values ​​for both ends and engine types.\n",
    ">\n",
    ">All of these were treated accordingly in order to cover all the available options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6aa910-0fbe-4b74-8e30-b2e13df36208",
   "metadata": {},
   "source": [
    "> We chose here to split into different cases as mentioned according to the distribution we saw.\n",
    ">\n",
    "> The cases are detailed in the comments in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08c58e87-6e11-464e-955b-958ee35d33c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['capacity_Engine'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "776dc1f8-6321-40e3-964e-10c7be519128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1474.000000\n",
       "mean      1665.293758\n",
       "std        822.018723\n",
       "min         13.000000\n",
       "25%       1292.000000\n",
       "50%       1500.000000\n",
       "75%       1800.000000\n",
       "max      15000.000000\n",
       "Name: capacity_Engine, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['capacity_Engine'] = data['capacity_Engine'].replace(',', '', regex=True).astype(pd.Int64Dtype())\n",
    "\n",
    "data['capacity_Engine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fd7c05f-9398-4e17-9cbd-89a4c40e32ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null: 26\n",
      "dtypes: Int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"null: {(data['capacity_Engine'].isnull().sum())}\")\n",
    "print(f\"dtypes: {data['capacity_Engine'].dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2710fed1-dfed-47e6-ac82-7f51829f88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle capacity_Engine column based on specified rules\n",
    "def handle_capacity_engine_column(data, use_median=False, neutral_value=None):\n",
    "    # Remove commas and convert to integer\n",
    "    data['capacity_Engine'] = data['capacity_Engine'].replace(',', '', regex=True).astype(pd.Int64Dtype())\n",
    "    \n",
    "    # Calculate median and mean with standard deviation\n",
    "    median_capacity = data['capacity_Engine'].median()\n",
    "    mean_capacity = data['capacity_Engine'].mean()\n",
    "    std_capacity = data['capacity_Engine'].std()\n",
    "    \n",
    "    # Function to handle each row\n",
    "    def adjust_engine_capacity(row):\n",
    "        if row['Engine_type'] == 'חשמלי':\n",
    "            # Check if within one standard deviation of the mean\n",
    "            if mean_capacity - std_capacity <= row['capacity_Engine'] <= mean_capacity + std_capacity:\n",
    "                return row['capacity_Engine']\n",
    "            else:\n",
    "                return neutral_value if neutral_value is not None else (mean_capacity if not use_median else median_capacity)\n",
    "        if pd.isna(row['capacity_Engine']):\n",
    "            return mean_capacity if not use_median else median_capacity\n",
    "        if row['capacity_Engine'] > 10000:\n",
    "            return row['capacity_Engine'] / 10\n",
    "        if row['capacity_Engine'] < 26:\n",
    "            return row['capacity_Engine'] * 100\n",
    "        if 0 <= row['capacity_Engine'] < 10:\n",
    "            return  mean_capacity if not use_median else median_capacity\n",
    "        if 26 < row['capacity_Engine'] < 800:\n",
    "            return mean_capacity if not use_median else median_capacity\n",
    "        return row['capacity_Engine']\n",
    "    \n",
    "    # Apply function to each row\n",
    "    data['capacity_Engine'] = data.apply(adjust_engine_capacity, axis=1)\n",
    "    data['capacity_Engine'] = data['capacity_Engine'].round(0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec51355-4d4f-4731-a0f7-09447acd4ce0",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec11'></a>\n",
    "\n",
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>Columns handling:</strong> <code>Prev_ownership , Curr_ownership , Description</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b466392-998b-4243-bc1d-a39da3b013a8",
   "metadata": {},
   "source": [
    "By the following actions on these columns we can implement a new feature:\n",
    "Ownership_Value based on the presence of specific keywords in the relevant columns,\n",
    "helping the predictive model in understanding potential factors that could affect the vehicle's price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9819299-6e32-4884-8671-a50dc507ba2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['פרטית', nan, 'ליסינג', 'מונית', 'לא מוגדר', 'חברה', 'השכרה',\n",
       "       'אחר', 'None', 'ממשלתי'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Prev_ownership\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83369f51-83db-4469-b50b-1cf679920d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['פרטית', nan, 'לא מוגדר', 'אחר', 'None', 'ליסינג', 'חברה', 'השכרה'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Curr_ownership\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e60e78a-3bc0-4098-b1c5-59be8788b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check ownership terms and assign values\n",
    "def assign_ownership_value(row):\n",
    "    ownership_terms_regex = r'ליסינג|השכרה|חברה'\n",
    "    columns_to_check = ['Prev_ownership', 'Curr_ownership']\n",
    "    \n",
    "    for col in columns_to_check:\n",
    "        if pd.notna(row[col]) and re.search(ownership_terms_regex, row[col]):\n",
    "            return 1  # Assign value 1 if match found\n",
    "\n",
    "    # Check only for \"ליסינג\" in the 'Description' column\n",
    "    if pd.notna(row['Description']) and re.search(r'\\bליסינג\\b', row['Description']):\n",
    "        return 1  # Assign value 1 if \"ליסינג\" found\n",
    "    \n",
    "    return 0  # Default value if no match found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004dba2e-c975-455a-a29d-34031637ca18",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec12'></a>\n",
    "\n",
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>Columns handling:</strong> <code> Area </code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37867169-1138-41b1-bac2-891769ea2ece",
   "metadata": {},
   "source": [
    "> The\n",
    "> <code> Area </code>\n",
    "> column represents geographical regions in the dataset, originally in Hebrew.\n",
    ">\n",
    "> We standardized and categorized these values to ensure consistency and usability in the predictive model. Here’s how we processed the\n",
    "> <code> Area </code>\n",
    ">column:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde9610-a855-4f71-aeb3-a664cbc3f9bf",
   "metadata": {},
   "source": [
    "> <u> 1. Standardization of Area Names:</u>\n",
    ">\n",
    "> ● We created a dictionary, \n",
    "> <code> hebrew_areas </code>,\n",
    "> to map various representations of area names to standardized Hebrew names.\n",
    ">\n",
    "> ● Using regular expressions, we replaced the area names in the\n",
    "> <code> Area </code>\n",
    ">column based on the\n",
    "> <code> hebrew_areas </code>\n",
    "> mappings.\n",
    ">\n",
    "> This step ensured that different representations of the same area were unified under a single name.\n",
    "\n",
    "> <u> 2. Categorization into Regions: </u>\n",
    ">\n",
    "> ● We further grouped these standardized area names into broader regions using the\n",
    "> <code> region_mappings </code>\n",
    "> dictionary.\n",
    ">\n",
    "> ● A new column,\n",
    "> <code> Area_new </code>\n",
    "> , was created to represent these broader regions based on the standardized area names.\n",
    "\n",
    "> <u> 3. Handling Missing Values: </u>\n",
    ">\n",
    "> ● We observed that some values in the <code> Area_new </code>\n",
    "> column were missing.\n",
    ">\n",
    "> To address this, we implemented a method to fill in these missing values based on the relative frequencies of the existing values in the\n",
    "> <code> Area_new </code>\n",
    "> column.\n",
    ">\n",
    "> ● The function\n",
    "> <code> fill_missing_area </code>\n",
    "> calculates the probabilities of each region occurring and fills in the missing values by randomly selecting a region\n",
    ">\n",
    "> according to these probabilities.\n",
    ">\n",
    "> This approach maintains the overall distribution of regions in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc0079ff-58fa-4e14-b49b-d2cdb6e7be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_area_column(data):\n",
    "    # Define mappings based on the provided Hebrew list\n",
    "    hebrew_areas = {\n",
    "        r\"\\bגליל(?:\\s+ועמקים)?\\b\": \"גליל ועמקים\",\n",
    "        r\"\\bחיפ(?:ה\\s+וחוף\\s+הכרמל)?\\b\": \"חיפה וחוף הכרמל\",\n",
    "        r\"\\bעמק\\s+יזרעאל\\b\": \"עמק יזרעאל\",\n",
    "        r\"\\bקריות\\b\": \"קריות\",\n",
    "        r\"\\bטבריה\\s+והסביבה\\b\": \"טבריה והסביבה\",\n",
    "        r\"\\bעכו\\s+-\\s+נהריה\\b\": \"עכו - נהריה\",\n",
    "        r\"\\bכרמיאל\\s+והסביבה\\b\": \"כרמיאל והסביבה\",\n",
    "        r\"\\bמושבים\\s+בצפון\\b\": \"מושבים בצפון\",\n",
    "        r\"\\bרעננה\\s+-\\s+כפר\\s+סבא\\b\": \"רעננה - כפר סבא\",\n",
    "        r\"\\bנתניה\\s+והסביבה\\b\": \"נתניה והסביבה\",\n",
    "        r\"\\bרמת\\s+השרון\\s+-\\s+הרצליה\\b\": \"רמת השרון - הרצליה\",\n",
    "        r\"\\bמושבים\\s+בשרון\\b\": \"מושבים בשרון\",\n",
    "        r\"\\bחדרה\\s+ותושבי\\s+עמק\\s+חפר\\b\": \"חדרה ותושבי עמק חפר\",\n",
    "        r\"\\bפרדס\\s+חנה\\s+-\\s+כרכור\\b\": \"פרדס חנה - כרכור\",\n",
    "        r\"\\bהוד\\s+השרון\\s+והסביבה\\b\": \"הוד השרון והסביבה\",\n",
    "        r\"\\bיישובי\\s+השומרון\\b\": \"יישובי השומרון\",\n",
    "        r\"\\bזכרון\\s+-\\s+בנימינה\\b\": \"זכרון - בנימינה\",\n",
    "        r\"\\bאזור\\s+השרון\\s+והסביבה\\b\": \"אזור השרון והסביבה\",\n",
    "        r\"\\bתל\\s+אביב\\b\": \"תל אביב\",\n",
    "        r\"\\bחולון\\s+-\\s+בת\\s+ים\\b\": \"חולון - בת ים\",\n",
    "        r\"\\bראשל\\\"צ\\s+והסביבה\\b\": \"ראשל\\\"צ והסביבה\",\n",
    "        r\"\\bרמת\\s+גן\\s+-\\s+גבעתיים\\b\": \"רמת גן - גבעתיים\",\n",
    "        r\"\\bפתח\\s+תקווה\\s+והסביבה\\b\": \"פתח תקווה והסביבה\",\n",
    "        r\"\\bראש\\s+העין\\s+והסביבה\\b\": \"ראש העין והסביבה\",\n",
    "        r\"\\bבני\\s+ברק\\b\": \"בני ברק\",\n",
    "        r\"\\bישובים\\s+במרכז\\b\": \"ישובים במרכז\",\n",
    "        r\"\\bירושלים\\s+והסביבה\\b\": \"ירושלים והסביבה\",\n",
    "        r\"\\bמודיעין\\s+והסביבה\\b\": \"מודיעין והסביבה\",\n",
    "        r\"\\bמושבים\\s+באזור\\s+ירושלים\\b\": \"מושבים באזור ירושלים\",\n",
    "        r\"\\bאשדוד\\s+-\\s+אשקלון\\b\": \"אשדוד - אשקלון\",\n",
    "        r\"\\bנס\\s+ציונה\\s+-\\s+רחובות\\b\": \"נס ציונה - רחובות\",\n",
    "        r\"\\bגדרה\\s+יבנה\\s+והסביבה\\b\": \"גדרה יבנה והסביבה\",\n",
    "        r\"\\bרמלה\\s+לוד\\b\": \"רמלה לוד\",\n",
    "        r\"\\bמושבים\\s+בשפלה\\b\": \"מושבים בשפלה\",\n",
    "        r\"\\bבאר\\s+שבע\\s+והסביבה\\b\": \"באר שבע והסביבה\",\n",
    "        r\"\\bאילת\\s+והערבה\\b\": \"אילת והערבה\",\n",
    "        r\"\\bמושבים\\s+בדרום\\b\": \"מושבים בדרום\"\n",
    "    }\n",
    "\n",
    "    # Replace using regular expressions\n",
    "    for pattern, replacement in hebrew_areas.items():\n",
    "        data[\"Area\"] = data[\"Area\"].str.replace(pattern, replacement, regex=True)\n",
    "\n",
    "    # Define mappings for regions based on the provided criteria\n",
    "    region_mappings = {\n",
    "        \"אזור צפון\": [\n",
    "            \"גליל ועמקים\",\n",
    "            \"חיפה וחוף הכרמל\",\n",
    "            \"עמק יזרעאל\",\n",
    "            \"קריות\",\n",
    "            \"טבריה והסביבה\",\n",
    "            \"עכו - נהריה\",\n",
    "            \"כרמיאל והסביבה\",\n",
    "            \"מושבים בצפון\"\n",
    "        ],\n",
    "        \"אזור השרון והסביבה\": [\n",
    "            \"רעננה - כפר סבא\",\n",
    "            \"נתניה והסביבה\",\n",
    "            \"רמת השרון - הרצליה\",\n",
    "            \"מושבים בשרון\",\n",
    "            \"חדרה ותושבי עמק חפר\",\n",
    "            \"פרדס חנה - כרכור\",\n",
    "            \"הוד השרון והסביבה\",\n",
    "            \"זכרון - בנימינה\",\n",
    "            \"אזור השרון והסביבה\"\n",
    "        ],\n",
    "        \"אזור מרכז\": [\n",
    "            \"תל אביב\",\n",
    "            \"חולון - בת ים\",\n",
    "            \"ראשל\\\"צ והסביבה\",\n",
    "            \"רמת גן - גבעתיים\",\n",
    "            \"פתח תקווה והסביבה\",\n",
    "            \"ראש העין והסביבה\",\n",
    "            \"בני ברק\",\n",
    "            \"ישובים במרכז\"\n",
    "        ],\n",
    "        \"אזור ירושלים והסביבה\": [\n",
    "            \"ירושלים והסביבה\",\n",
    "            \"מודיעין והסביבה\",\n",
    "            \"מושבים באזור ירושלים\"\n",
    "        ],\n",
    "        \"אזור השפלה והסביבה\": [\n",
    "            \"אשדוד - אשקלון\",\n",
    "            \"נס ציונה - רחובות\",\n",
    "            \"גדרה יבנה והסביבה\",\n",
    "            \"רמלה לוד\",\n",
    "            \"מושבים בשפלה\"\n",
    "        ],\n",
    "        \"אזור דרום\": [\n",
    "            \"באר שבע והסביבה\",\n",
    "            \"אילת והערבה\",\n",
    "            \"מושבים בדרום\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Create a new column \"Region\" based on mappings\n",
    "    data[\"Area_new\"] = None  # Initialize the new column\n",
    "\n",
    "    for region, areas in region_mappings.items():\n",
    "        data.loc[data[\"Area\"].isin(areas), \"Area_new\"] = region\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bac15f5-49c6-4462-aa15-a89a743ec4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_area(data):\n",
    "    # Calculate value counts and probabilities\n",
    "    value_counts = data['Area_new'].value_counts(normalize=True)\n",
    "    \n",
    "    # Extract categories and probabilities\n",
    "    categories = value_counts.index.tolist()\n",
    "    probabilities = value_counts.values.tolist()\n",
    "    \n",
    "    # Function to fill missing values based on probabilities\n",
    "    def fill_with_probability():\n",
    "        return np.random.choice(categories, p=probabilities)\n",
    "    \n",
    "    # Apply the function to fill missing values\n",
    "    data['Area_new'] = data['Area_new'].apply(lambda x: fill_with_probability() if pd.isna(x) else x)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8672a0-6320-49b3-884f-820608f072c8",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec13'></a>\n",
    "\n",
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>Columns handling:</strong> <code> Km </code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce148add-df79-424e-8ee9-95d436caddf3",
   "metadata": {},
   "source": [
    "> __Removing commas and spaces:__ This step removes any commas and spaces from the Km values and converts them to strings.\n",
    "> \n",
    "> __Removing non-numeric characters:__ This step removes any non-numeric characters from the Km values.\n",
    "> \n",
    "> __Converting to numeric:__ The cleaned Km values are converted to numeric values. Any non-convertible values are set to 0.\n",
    "> \n",
    "> __Rounding to whole numbers:__ The numeric Km values are rounded to the nearest whole number.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e93fc3-4f7d-4f70-832f-af9696a39cea",
   "metadata": {},
   "source": [
    "\n",
    "> __Handle zero Km values for cars not from the current year:__\n",
    ">\n",
    "> If the vehicle is not from the current year and its Km value is 0, it is updated\n",
    ">\n",
    "> based on the vehicle's age and an average yearly distance of 16700 km.\n",
    "> \n",
    "> __Handle 2 or 3-digit Km values:__\n",
    ">\n",
    "> For vehicles with Km values between 10 and 999,\n",
    "> \n",
    "> the function calculates a temporary value by adding three zeros.\n",
    "> \n",
    "> This value is checked against upper and lower limits based on the vehicle's age and the standard deviation of the Km values. If it falls within the\n",
    ">\n",
    "> limits, the temporary value is used; otherwise, the average of the limits is used.\n",
    ">\n",
    "> __Handle 4-digit Km values for cars not from the last two years:__\n",
    ">\n",
    "> For vehicles older than two years with Km values between 1000 and 5099, the Km\n",
    ">\n",
    "> value is multiplied by 10.\n",
    ">\n",
    "> __Handle Km values for cars from the last two years with hand number > 1:__\n",
    ">\n",
    "> For vehicles from the last two years with more than one previous owner\n",
    ">\n",
    "> and Km values below 100000, the Km value is multiplied by 10.\n",
    ">\n",
    "> __Fill missing values:__\n",
    ">\n",
    "> Any remaining missing values in the Km column are filled with the median or mean value, based on the use_median parameter.\n",
    ">\n",
    "> __Handle outliers using IQR method:__\n",
    ">\n",
    "> Outliers in the Km values are capped using the Interquartile Range (IQR) method.\n",
    ">\n",
    "> Values above the upper bound are capped at the upper bound, and values below the lower bound are capped at the lower bound.\n",
    ">\n",
    "> This process ensures that the Km column is cleaned, standardized, and handled appropriately for further analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11adb49c-824d-4492-8a18-1844363accf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Km'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fca5a725-1cd4-4683-979c-6e24013b3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_km_column(data):\n",
    "    # Remove commas, spaces, and convert to string\n",
    "    data['Km'] = data['Km'].astype(str).replace(',', '', regex=True).str.strip()\n",
    "    \n",
    "    # Remove non-numeric characters\n",
    "    data['Km'] = data['Km'].str.replace(r'\\D+', '', regex=True)\n",
    "    \n",
    "    # Convert to numeric, handling non-numeric values\n",
    "    data['Km'] = pd.to_numeric(data['Km'], errors='coerce').fillna(0)\n",
    "\n",
    "    # Round to whole numbers\n",
    "    data['Km'] = data['Km'].round().astype(int)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9daae74d-31f3-4a1d-879f-fa68d221159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_km_column(data, use_median=True):\n",
    "    # Clean the Km column\n",
    "    data = clean_km_column(data)\n",
    "    \n",
    "    # Define the current year\n",
    "    current_year = data['Year'].max()\n",
    "    \n",
    "    # Add a column to indicate if the row has been processed\n",
    "    data['processed'] = False\n",
    "    \n",
    "    # Iterate over each row to apply conditions\n",
    "    for idx, row in data.iterrows():\n",
    "        if row['Km'] <= 9 and row['Year'] < current_year and not row['processed']:\n",
    "            data.at[idx, 'Km'] = (current_year - row['Year']) * 16700\n",
    "            data.at[idx, 'processed'] = True\n",
    "            continue  # Move to the next row\n",
    "        \n",
    "        if 10 <= row['Km'] < 1000 and not row['processed']:\n",
    "            temp_km = row['Km'] * 1000\n",
    "            vehicle_age = current_year - row['Year']\n",
    "            std_dev = data['Km'].std()\n",
    "            lower_limit = (vehicle_age - 0.5) * 16700 - (0.5 * std_dev)\n",
    "            upper_limit = (vehicle_age + 0.5) * 16700 + (0.5 * std_dev)\n",
    "            \n",
    "            if lower_limit <= temp_km <= upper_limit:\n",
    "                data.at[idx, 'Km'] = temp_km\n",
    "            else:\n",
    "                data.at[idx, 'Km'] = (lower_limit + upper_limit) / 2\n",
    "            data.at[idx, 'processed'] = True\n",
    "            continue  # Move to the next row\n",
    "        \n",
    "        if row['Year'] < current_year - 1 and 1000 <= row['Km'] < 10000 and not row['processed']:\n",
    "            data.at[idx, 'Km'] = row['Km'] * 10\n",
    "            data.at[idx, 'processed'] = True\n",
    "            continue  # Move to the next row\n",
    "        \n",
    "        if row['Year'] in [current_year, current_year - 1] and row['Hand'] > 1 and row['Km'] < 100000 and not row['processed']:\n",
    "            data.at[idx, 'Km'] = row['Km'] * 10\n",
    "            data.at[idx, 'processed'] = True\n",
    "            continue  # Move to the next row\n",
    "    \n",
    "    # Remove the 'processed' column as it is no longer needed\n",
    "    data.drop(columns=['processed'], inplace=True)\n",
    "    \n",
    "    # Fill missing values with median or mean\n",
    "    if use_median:\n",
    "        fill_value = data['Km'].median()\n",
    "    else:\n",
    "        fill_value = data['Km'].mean()\n",
    "\n",
    "    data['Km'] = data['Km'].fillna(fill_value)\n",
    "    \n",
    "    # Handle outliers using IQR method\n",
    "    Q1 = data['Km'].quantile(0.25)\n",
    "    Q3 = data['Km'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Cap the outliers\n",
    "    data.loc[data['Km'] > upper_bound, 'Km'] = upper_bound\n",
    "    data.loc[data['Km'] < lower_bound, 'Km'] = lower_bound\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76535578-9fef-4012-8c33-103fe0cf784f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec14'></a>\n",
    "\n",
    "<div style=\"background-color:#99D8FF; height: 5px; width: 100%; border-radius: 50px;\"></div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<strong>prepare_data function:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08738d6a-bb71-4e5b-9aa7-03c073cfd32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \n",
    "    # remove_Duplicates\n",
    "    data = remove_Duplicates(data)\n",
    "    \n",
    "    # Standardize manufacturer names\n",
    "    data['manufactor'] = data['manufactor'].apply(standardize_manufactor)\n",
    "\n",
    "    # Clean manufactor name from model col\n",
    "    data = remove_manufactor_name_in_model_col(data)\n",
    "    \n",
    "    # Clean and standardize the model names    \n",
    "    data['model'] = data['model'].apply(clean_model_name)\n",
    "    \n",
    "    # converting to lowercase and removing extra spaces\n",
    "    data['model'] = data['model'].apply(normalize_model_name)\n",
    "\n",
    "    # Handle Hand column\n",
    "    data = handle_hand_column(data)\n",
    "    \n",
    "    # Handle Gear column\n",
    "    data = handle_gear_column(data)\n",
    "\n",
    "    # Handle engine_type column\n",
    "    data = handle_engine_type_column(data)\n",
    "\n",
    "    # Handle capacity_engine column\n",
    "    data = handle_capacity_engine_column(data)\n",
    "\n",
    "    # Create a new column 'Ownership_Value' based on regex matches\n",
    "    data['Ownership_Value'] = data.apply(assign_ownership_value, axis=1).astype('category')\n",
    "\n",
    "    # Handle Area column\n",
    "    data = handle_area_column(data)\n",
    "\n",
    "    # Fill missing values in 'Area_new' based on probabilities\n",
    "    data = fill_missing_area(data)\n",
    "\n",
    "    # Handle km column\n",
    "    data = handle_km_column(data)\n",
    "\n",
    "\n",
    "    # Bin the Year column dynamically\n",
    "    data = bin_year_column(data, num_bins=5)\n",
    "\n",
    "    \n",
    "    data = data.drop(columns=['Prev_ownership','Curr_ownership','Area','City',\n",
    "                              'Pic_num','Cre_date','Repub_date','Description',\n",
    "                              'Test', 'Supply_score','Color','Gear'])\n",
    "                             #,'Year'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb317af3-5412-42f1-bcb3-45bdcfd2d16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufactor</th>\n",
       "      <th>Year</th>\n",
       "      <th>model</th>\n",
       "      <th>Hand</th>\n",
       "      <th>capacity_Engine</th>\n",
       "      <th>Engine_type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Km</th>\n",
       "      <th>Auto_Gear</th>\n",
       "      <th>Ownership_Value</th>\n",
       "      <th>Area_new</th>\n",
       "      <th>Year_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>יונדאי</td>\n",
       "      <td>2015</td>\n",
       "      <td>i35</td>\n",
       "      <td>2</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>בנזין</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>144000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>אזור השרון והסביבה</td>\n",
       "      <td>2014-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ניסאן</td>\n",
       "      <td>2018</td>\n",
       "      <td>מיקרה</td>\n",
       "      <td>1</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>בנזין</td>\n",
       "      <td>49000.0</td>\n",
       "      <td>69000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>אזור השרון והסביבה</td>\n",
       "      <td>2017-2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>סוזוקי</td>\n",
       "      <td>2010</td>\n",
       "      <td>סוויפט</td>\n",
       "      <td>1</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>בנזין</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>אזור צפון</td>\n",
       "      <td>1983-2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>טויוטה</td>\n",
       "      <td>2016</td>\n",
       "      <td>אוריס</td>\n",
       "      <td>1</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>בנזין</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>27300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>אזור השפלה והסביבה</td>\n",
       "      <td>2016-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>קיה</td>\n",
       "      <td>2012</td>\n",
       "      <td>פיקנטו</td>\n",
       "      <td>1</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>בנזין</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>אזור מרכז</td>\n",
       "      <td>2011-2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  manufactor  Year   model  Hand  capacity_Engine Engine_type    Price  \\\n",
       "0     יונדאי  2015     i35     2           1600.0       בנזין  51000.0   \n",
       "1      ניסאן  2018   מיקרה     1           1200.0       בנזין  49000.0   \n",
       "2     סוזוקי  2010  סוויפט     1           1450.0       בנזין  22500.0   \n",
       "3     טויוטה  2016   אוריס     1           1600.0       בנזין  63000.0   \n",
       "4        קיה  2012  פיקנטו     1           1248.0       בנזין  37000.0   \n",
       "\n",
       "       Km Auto_Gear Ownership_Value            Area_new Year_range  \n",
       "0  144000         0               0  אזור השרון והסביבה  2014-2016  \n",
       "1   69000         0               0  אזור השרון והסביבה  2017-2024  \n",
       "2  145000         0               0           אזור צפון  1983-2011  \n",
       "3   27300         1               0  אזור השפלה והסביבה  2016-2017  \n",
       "4   70000         0               0           אזור מרכז  2011-2014  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the data_prep function to the dataset\n",
    "prepared_data = prepare_data(data)\n",
    "\n",
    "# Display a preview of the prepared data\n",
    "prepared_data.head()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3022752a-f3ed-475f-a305-1402c9e256c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 12)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85ae2d7a-4d0f-47a3-bfc9-967ee08e1e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['manufactor', 'Year', 'model', 'Hand', 'capacity_Engine', 'Engine_type',\n",
       "       'Price', 'Km', 'Auto_Gear', 'Ownership_Value', 'Area_new',\n",
       "       'Year_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a37ee-4ba9-4994-8900-185a3429f8fc",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec15'></a>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:25px;\n",
    "            background-color:#99D8FF;font-size:150%; \n",
    "            letter-spacing:1.0px;background-image: url\">\n",
    "    <p style=\"padding: 8px;text-align: center;color:#464646; border-radius: 10px; padding-top: 5px; padding-bottom: 5px;\"><b><b><span style='color:#99D8FF''></span></b> Data Preparation and ElasticNet Model Pipeline. </b></p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8bf4f-213a-4ea2-8ae4-092a83d6b80b",
   "metadata": {},
   "source": [
    "> <strong>Step 1: Prepare Data<strong>\n",
    "> \n",
    "> 'prepared_data' is the DataFrame after all processing.\n",
    ">\n",
    "> Separate the features (X) and the target variable (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7503823-43ab-4aec-b1a7-b7052d67e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Assuming 'prepared_data' is the DataFrame after all processing\n",
    "X = prepared_data.drop('Price', axis=1)\n",
    "y = prepared_data['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18501cf7-55f6-4428-80a0-b6c0f0242606",
   "metadata": {},
   "source": [
    "> <strong>Step 2: Identify Numerical and Categorical Features & Split the data into training and test sets<strong>\n",
    ">\n",
    "> Identify which columns are numerical and which are categorical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6032bf3-d90a-4378-b7b6-f48407590b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Hand', 'capacity_Engine', 'Km']\n",
      "['manufactor', 'model', 'Engine_type', 'Auto_Gear', 'Ownership_Value', 'Area_new', 'Year_range']\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # random_state = 42\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numerical_types = ['int','int16','int32','int64','float','float16','float32','float64']\n",
    "numerical_features = X.select_dtypes(include= numerical_types).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(numerical_features)\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d178622d-6ede-4cb0-8b43-7176bed27869",
   "metadata": {},
   "source": [
    "> <strong>Step 3: Define Pipelines<strong>\n",
    ">\n",
    "> Define separate pipelines for numerical and categorical features to handle preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05e30c1b-36c3-4e74-a766-71dd90275e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical pipeline\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d462491-9a2c-4a27-820b-ca31c3cf6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical pipeline\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411126f8-d23d-4835-900f-e362f48afc51",
   "metadata": {},
   "source": [
    "> <strong>Step 4: Combine Pipelines into a ColumnTransformer<strong>\n",
    ">\n",
    "> Combine the numerical and categorical pipelines into a single `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b8dba7b-c723-40fa-937e-dff2c73e31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numerical and categorical pipelines into a single ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb8efa-8438-4d4b-9ac6-7c2827595ec3",
   "metadata": {},
   "source": [
    "> __Step 5: Define ElasticNet Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70f586c7-0edb-4164-8f7d-861dc192b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ElasticNet model\n",
    "elastic_net = ElasticNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c75a3a0-a6eb-4e99-98cb-dd849a1209df",
   "metadata": {},
   "source": [
    "> __Step 6: Create Model Pipeline__\n",
    "> \n",
    "> We create a pipeline that combines preprocessing and the ElasticNet model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "df410d3f-5d32-4ca4-be01-6b4b940fb5d1",
   "metadata": {},
   "source": [
    "# Create the model pipeline with SVD\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svd', svd),\n",
    "    ('model', elastic_net)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd60b01a-ee6f-40f7-a1d4-48b2200f6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', elastic_net)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a49eda-3580-41c1-a00d-2bec63c00db1",
   "metadata": {},
   "source": [
    "> __Step 7: Define Parameter Grid for GridSearchCV and perform GridSearchCV__\n",
    ">\n",
    "> We define the parameter grid for GridSearchCV to search for the best hyperparameters.\n",
    ">\n",
    "> Then perform GridSearchCV to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a95d71cc-f6c3-4aee-84dc-01bfdec883e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'model__alpha': [0.00001,0.00001 ,0.0001, 0.001, 0.01, 0.1],\n",
    "    'model__l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_pipeline, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2a003-75bd-4f20-8cb6-66d743cc19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the GridSearchCV According to train set \n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dee7f9-8076-41c4-997e-086eeb51fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d23dc5a-343e-4fc3-ad4d-30c791ec9b2d",
   "metadata": {},
   "source": [
    "> __Step 8: Extract Best Model and Parameters__\n",
    "> \n",
    "> Extract the best model and its parameters from the grid search and defining the model by the parameters,\n",
    "> \n",
    "> then we will update the pipeline with the best model we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4f51c-41d7-46eb-b59e-df80ea6acf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Extract the best alpha and l1_ratio\n",
    "best_alpha = best_params['model__alpha']\n",
    "best_l1_ratio = best_params['model__l1_ratio']\n",
    "\n",
    "# Create the ElasticNet model with best parameters\n",
    "final_elastic_net = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "\n",
    "# Update the pipeline with the best model\n",
    "final_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', final_elastic_net)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e710a0a-4c1d-4d6c-92ac-7544b7cb0c7a",
   "metadata": {},
   "source": [
    "> __Step 9: Fit the final model pipeline on the training data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b76c3-e13b-405c-9be0-5055fa58278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab9dea-f814-4fcf-babd-4de48cdc4967",
   "metadata": {},
   "source": [
    "> __Step 10: Perform 10-Fold Cross-Validation__\n",
    "> \n",
    "> Perform `10-fold cross-validation` and print the `RMSE` scores for each fold.\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39f0d0-b11b-4042-9e00-5f38630cf2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "cross_val_scores = cross_val_score(final_pipeline, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "cross_val_rmse_scores = np.sqrt(-cross_val_scores)\n",
    "\n",
    "print(f\"Cross-Validation RMSE scores: {cross_val_rmse_scores}\")\n",
    "print(f\"Mean Cross-Validation RMSE: {cross_val_rmse_scores.mean():.2f}\")\n",
    "print(f\"Standard Deviation of Cross-Validation RMSE: {cross_val_rmse_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f1f23b-d8ca-4cc9-a5bc-8376d32394d2",
   "metadata": {},
   "source": [
    ">__Step 11: Preprocess Data and Get Feature Names__\n",
    ">\n",
    "> Preprocess the data and get the feature names after encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22c570-7e4c-4487-9119-9bea02bd8161",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Get the Preprocessor and Model: \n",
    "\n",
    "Extract the preprocessor and the ElasticNet model from the final pipeline.\n",
    "'''\n",
    "\n",
    "# Get the preprocessor and model from the best pipeline\n",
    "preprocessor = final_pipeline.named_steps['preprocessor']\n",
    "elastic_net = final_pipeline.named_steps['model']\n",
    "\n",
    "'''\n",
    "2. Preprocess the Data: \n",
    "\n",
    "Preprocess the entire feature set X using the preprocessor to ensure it matches the format used during training.\n",
    "'''\n",
    "# Preprocess the data\n",
    "X_processed = preprocessor.transform(X)\n",
    "\n",
    "''' \n",
    "3. Get Feature Names: \n",
    "Retrieve the feature names after preprocessing. \n",
    "For numerical features, we simply use their column names. \n",
    "For categorical features, we get the names of the dummy variables created by OneHotEncoder\n",
    "'''\n",
    "# Get feature names after preprocessing\n",
    "onehot_feature_names = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "feature_names = numerical_features + list(onehot_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9091d-ead8-45a4-86db-35437a8efa91",
   "metadata": {},
   "source": [
    ">__Step 12: Calculate Feature Importance__\n",
    ">\n",
    "> In this step, we calculate the importance of each feature based on the coefficients from the `ElasticNet` model.\n",
    ">\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34014f1-9a7d-4480-9930-ba470075b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4. Calculate Feature Importance:\n",
    "Create a DataFrame with the feature names and their corresponding absolute coefficients from the ElasticNet model. \n",
    "The coefficients represent the importance of each feature.\n",
    "'''\n",
    "\n",
    "# Feature importance for ElasticNet (coefficient magnitude)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': np.abs(elastic_net.coef_)\n",
    "})\n",
    "\n",
    "\n",
    "'''\n",
    "5. Group Feature Importances: \n",
    "Group the feature importances by their original categorical feature. \n",
    "This step involves creating a dictionary to map dummy variables back to their original categorical feature and summing the importances.\n",
    "'''\n",
    "\n",
    "# Create feature groups dictionary\n",
    "feature_groups = {}\n",
    "for feature in categorical_features:\n",
    "    dummies = [col for col in feature_names if col.startswith(feature)]\n",
    "    for dummy in dummies:\n",
    "        feature_groups[dummy] = feature\n",
    "\n",
    "# Group importances\n",
    "grouped_importance = feature_importance.groupby(\n",
    "    feature_importance['feature'].map(lambda x: feature_groups.get(x, x))\n",
    ").sum().sort_values('importance', ascending=False)\n",
    "\n",
    "'''\n",
    "6. Determine Impact: \n",
    "For each grouped feature, \n",
    "Calculate the overall impact (positive or negative) by summing the signed coefficients.\n",
    "'''\n",
    "\n",
    "# Calculate impact\n",
    "grouped_importance['impact'] = 'Neutral'  # Default value\n",
    "\n",
    "for index in grouped_importance.index:\n",
    "    mask = feature_importance['feature'].map(lambda x: feature_groups.get(x, x)) == index\n",
    "    if mask.any():\n",
    "        relevant_features = feature_importance.loc[mask, 'feature']\n",
    "        relevant_coefs = [elastic_net.coef_[feature_names.index(feat)] for feat in relevant_features]\n",
    "        coef_sum = (feature_importance.loc[mask, 'importance'] * np.sign(relevant_coefs)).sum()\n",
    "        grouped_importance.loc[index, 'impact'] = 'Positive' if coef_sum >= 0 else 'Negative'\n",
    "\n",
    "'''\n",
    "Print Top 5 Most Important Grouped Features: \n",
    "Print the top 5 grouped features along with their importance and impact.\n",
    "'''\n",
    "\n",
    "print(\"\\nTop 5 most important grouped features with impact:\")\n",
    "for index, row in grouped_importance.head(5).iterrows():\n",
    "    feature = index\n",
    "    importance = row['importance']\n",
    "    impact = row['impact']\n",
    "    print(f\"{feature}: {importance:.4f} ({impact})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb65b0-a6b2-40aa-9c41-bd0e5a2c09be",
   "metadata": {},
   "source": [
    "> __Step 13: Make Predictions and Evaluate the Model__\n",
    "> \n",
    "> Make predictions on the test set and evaluate the model using metrics like `RMSE`, `R-squared`, `MAE`, and `MAPE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecfa186-bbc3-4e11-a686-2eeea2d5b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]\n",
    "p = X_test.shape[1]\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Adjusted R-squared: {adjusted_r2:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac8804-0a10-4f3b-afb5-5b500047573f",
   "metadata": {},
   "source": [
    "> __Step 14: Perform K-Fold Cross-Validation Again__\n",
    "> \n",
    "> Finally, perform k-fold cross-validation again to ensure the robustness of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d342a9c-b33d-425b-887c-57f67578d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(final_pipeline, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert to positive RMSE\n",
    "rmse_scores = np.sqrt(-cv_scores)\n",
    "print(\"RMSE scores for each fold: \", rmse_scores)\n",
    "print(\"Mean RMSE: \", rmse_scores.mean())\n",
    "print(\"Standard Deviation of RMSE: \", rmse_scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6303eb-e74d-452a-a831-97a149231685",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id='sec16'></a>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:25px;\n",
    "            background-color:#99D8FF;font-size:150%; \n",
    "            letter-spacing:1.0px;background-image: url\">\n",
    "    <p style=\"padding: 8px;text-align: center;color:#464646; border-radius: 10px; padding-top: 5px; padding-bottom: 5px;\"><b><b><span style='color:#99D8FF''></span></b> Analyze the outputs. </b></p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407a070-98df-46c5-b9fc-a473c1304f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Plotting Predicted vs. Actual Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Predicted vs. Actual Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35c67e-82d4-4e08-85f1-e0df28ee9c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Calculate statistics\n",
    "residuals_skewness = skew(residuals)\n",
    "residuals_mean = np.mean(residuals)\n",
    "residuals_std = np.std(residuals)\n",
    "\n",
    "# Plotting the distribution of residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, bins=30, kde=True, color='#99D8FF')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Skewness of the residuals: {residuals_skewness:.2f}\")\n",
    "print(f\"Mean of the residuals: {residuals_mean:.2f}\")\n",
    "print(f\"Standard deviation of the residuals: {residuals_std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f39b95-b90c-4551-8b5b-b8046f951be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Residuals vs. Predicted Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs. Predicted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccabc6d-ed85-4b28-8983-3f0ad2725702",
   "metadata": {},
   "source": [
    "### Compare Training and Validation Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8755e37-8936-4f90-a7f0-aa7437ee8011",
   "metadata": {},
   "source": [
    "> Here, the test RMSE is higher than the training RMSE, R-squared Lower than the training R-squared, which suggests overfitting.\n",
    ">\n",
    "> which makes sense for a relatively small data size - the model despite this shows __stable performance.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf4f22c-a599-4481-9b54-4b5503e5a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the training set\n",
    "y_train_pred = final_pipeline.predict(X_train)\n",
    "\n",
    "# Calculate training metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_mape = np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100\n",
    "\n",
    "# Calculate Adjusted R-squared for training set\n",
    "n_train = X_train.shape[0]\n",
    "p_train = X_train.shape[1]\n",
    "train_adjusted_r2 = 1 - (1 - train_r2) * (n_train - 1) / (n_train - p_train - 1)\n",
    "\n",
    "print(\"Step 1: Compare Training and Validation Errors\")\n",
    "print(f\"Training RMSE: {train_rmse:.2f}\")\n",
    "print(f\"Training R-squared: {train_r2:.2f}\")\n",
    "print(f\"Training Adjusted R-squared: {train_adjusted_r2:.2f}\")\n",
    "print(f\"Training MAE: {train_mae:.2f}\")\n",
    "print(f\"Training MAPE: {train_mape:.2f}%\")\n",
    "\n",
    "print(f\"Test RMSE: {rmse:.2f}\")\n",
    "print(f\"Test R-squared: {r2:.2f}\")\n",
    "print(f\"Test Adjusted R-squared: {adjusted_r2:.2f}\")\n",
    "print(f\"Test MAE: {mae:.2f}\")\n",
    "print(f\"Test MAPE: {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b55603-773a-46e6-8858-49a41c84a39b",
   "metadata": {},
   "source": [
    "### Analyze Learning Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd5e8b9-1939-44fc-9bdc-33279086dd2c",
   "metadata": {},
   "source": [
    "> Plot learning curves to visualize how the model performance (error) changes with varying sizes of the training dataset.\n",
    ">\n",
    "> The training error increases with the training size but stabilizes at around 8500 RMSE.\n",
    ">\n",
    "> The validation error decreases with more training data but stabilizes at a higher error rate (~12000 RMSE).\n",
    ">\n",
    "> The gap between the training and validation errors suggests that the model might benefit from more data or better regularization.\n",
    ">\n",
    "> This claim connects with the insight above due to the lack of data for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f64230-b23f-4b8e-99e2-882c74540344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    final_pipeline, X, y, cv=10, scoring='neg_mean_squared_error', train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "\n",
    "train_errors = np.sqrt(-train_scores)\n",
    "val_errors = np.sqrt(-val_scores)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_sizes, train_errors.mean(axis=1), 'o-', label=\"Training Error\")\n",
    "plt.plot(train_sizes, val_errors.mean(axis=1), 'o-', label=\"Validation Error\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.title(\"Learning Curves\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb92e9-45cd-411b-9573-31b6378551e6",
   "metadata": {},
   "source": [
    "#### Plot validation curves to understand how the model performance changes with different hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d9d23-d708-4315-ae67-e9c2fb27cb51",
   "metadata": {},
   "source": [
    "Due to the long running time for analysis the cell was switched to Raw mode\n",
    "From the output of the graph, we deduced the range l1 desired for us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec43913-c954-481e-82e7-acf78a46b709",
   "metadata": {},
   "source": [
    "> The training error remains relatively low for smaller alpha values and increases as alpha increases.\n",
    ">\n",
    "> The validation error is lower for smaller alpha values and increases significantly as alpha increases beyond a certain point.\n",
    ">\n",
    "> The resulting range is above in the model build"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91721bfd-d47e-4c49-99f4-de2185c82be9",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = np.logspace(-5, 2, 50)\n",
    "train_scores, val_scores = validation_curve(\n",
    "    final_pipeline, X, y, param_name=\"model__alpha\", param_range=param_range, cv=10, scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "train_errors = np.sqrt(-train_scores)\n",
    "val_errors = np.sqrt(-val_scores)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(param_range, train_errors.mean(axis=1), 'o-', label=\"Training Error\")\n",
    "plt.plot(param_range, val_errors.mean(axis=1), 'o-', label=\"Validation Error\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.title(\"Validation Curves for Alpha\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
